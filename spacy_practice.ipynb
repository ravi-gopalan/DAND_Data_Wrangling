{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_practice.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-gopalan/DAND_Data_Wrangling/blob/master/spacy_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXazOFp8iz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a95f467f-7f2f-4a8e-8aa7-b48539b88cc6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHFfNrsC8zKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9205608-1acf-4d4e-9c6f-be09dc8f21f6"
      },
      "source": [
        "cd '/gdrive/My Drive/abv_reviews'"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/abv_reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKXwPwMY86KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bfac4e6-1689-482a-b3b2-383f8ab6283d"
      },
      "source": [
        "ls"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/  \u001b[01;34mpending_images\u001b[0m/  reviews_text.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ABgn0J8niK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "from pandas.io.json import json_normalize\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0OtpPq79PoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e915ea1-9d68-455f-a4ba-5f6ef06998b2"
      },
      "source": [
        "import spacy\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "import en_core_web_lg\n",
        "from spacy import displacy\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in_zzznz9hpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg', disable = ['ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dlNGbSOAQN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "f64f87e6-4c72-4b3f-bee8-53d949a5a3a6"
      },
      "source": [
        "df_review = pd.read_csv('reviews_text.csv')\n",
        "df_review.info()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (12,25,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56156 entries, 0 to 56155\n",
            "Data columns (total 36 columns):\n",
            "Unnamed: 0           56156 non-null int64\n",
            "_id                  56156 non-null object\n",
            "updatedAt            56156 non-null object\n",
            "createdAt            56156 non-null object\n",
            "originality          56156 non-null int64\n",
            "value                56156 non-null int64\n",
            "nutrition            56156 non-null int64\n",
            "presentation         56156 non-null int64\n",
            "taste                56156 non-null int64\n",
            "text                 56155 non-null object\n",
            "dish                 56156 non-null object\n",
            "type                 56156 non-null object\n",
            "isPublished          5885 non-null object\n",
            "user                 56156 non-null object\n",
            "restaurant           56156 non-null object\n",
            "images               56156 non-null object\n",
            "likes                56156 non-null object\n",
            "__v                  56156 non-null int64\n",
            "comments             56156 non-null object\n",
            "likesCount           56156 non-null int64\n",
            "tags                 56156 non-null object\n",
            "country              55340 non-null object\n",
            "commentsCount        56155 non-null float64\n",
            "overall              56156 non-null float64\n",
            "rating               56156 non-null object\n",
            "isProduct            22192 non-null object\n",
            "status               56156 non-null object\n",
            "textTags             56156 non-null object\n",
            "isPoked              48520 non-null object\n",
            "platform             38124 non-null object\n",
            "moderatedAt          18814 non-null object\n",
            "moderator            18814 non-null object\n",
            "brand                64 non-null object\n",
            "product              64 non-null object\n",
            "feedback             4512 non-null object\n",
            "moderationReasons    6915 non-null object\n",
            "dtypes: float64(2), int64(8), object(26)\n",
            "memory usage: 15.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7q6tGZ6DKRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_text = df_review[['_id','text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7zh5hVgDRDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "6d08b256-1207-40e7-8717-3c31ec284eac"
      },
      "source": [
        "review_text"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59e599911747c90004ba8586</td>\n",
              "      <td>Burger joint offers a wide range of cheeseburg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59ff122b8b04fd0004df6c78</td>\n",
              "      <td>It was really good. The mushroom broth was esp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5dc251e552e7e90020b6adfb</td>\n",
              "      <td>$8.90 for sesame rice, mushroom rendang, curry...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5d35cf4049745d0004c68de3</td>\n",
              "      <td>2 mains + 1 green rice bento from greendot. Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5d304e9264f5e5000423b75b</td>\n",
              "      <td>The lion mane mushroom rendang is so delicious...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56151</th>\n",
              "      <td>5de6f2e989849e0020715f6b</td>\n",
              "      <td>Good love office treats! These are perfectly s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56152</th>\n",
              "      <td>5de6f4cf89849e0020716021</td>\n",
              "      <td>Very tasty! Crisp fresh vegetables with fried ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56153</th>\n",
              "      <td>5de6f53d89849e002071605c</td>\n",
              "      <td>Delicious! Creamy coconut milk red curry sauce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56154</th>\n",
              "      <td>5de6f69989849e00207160ca</td>\n",
              "      <td>Absolutely delicious! Great if youâ€™re on the r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56155</th>\n",
              "      <td>5de6f79589849e0020716151</td>\n",
              "      <td>(Added the vegan coco whip on top at home)\\nGo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56156 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            _id                                               text\n",
              "0      59e599911747c90004ba8586  Burger joint offers a wide range of cheeseburg...\n",
              "1      59ff122b8b04fd0004df6c78  It was really good. The mushroom broth was esp...\n",
              "2      5dc251e552e7e90020b6adfb  $8.90 for sesame rice, mushroom rendang, curry...\n",
              "3      5d35cf4049745d0004c68de3  2 mains + 1 green rice bento from greendot. Re...\n",
              "4      5d304e9264f5e5000423b75b  The lion mane mushroom rendang is so delicious...\n",
              "...                         ...                                                ...\n",
              "56151  5de6f2e989849e0020715f6b  Good love office treats! These are perfectly s...\n",
              "56152  5de6f4cf89849e0020716021  Very tasty! Crisp fresh vegetables with fried ...\n",
              "56153  5de6f53d89849e002071605c  Delicious! Creamy coconut milk red curry sauce...\n",
              "56154  5de6f69989849e00207160ca  Absolutely delicious! Great if youâ€™re on the r...\n",
              "56155  5de6f79589849e0020716151  (Added the vegan coco whip on top at home)\\nGo...\n",
              "\n",
              "[56156 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD6MKsGmTq1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48700ed2-ec38-4981-9a40-21ab4cfb2346"
      },
      "source": [
        "# Select a random review from the corpus\n",
        "check = random.randint(0,20000)\n",
        "review_sample = review_text['text'][check:check+5]\n",
        "#print(review_sample)\n",
        "\n",
        "# convert that into nlp\n",
        "df_token = pd.DataFrame()\n",
        "\n",
        "stop_word_list = []\n",
        "punctuation_list = []\n",
        "non_english_list = []\n",
        "det_list = []\n",
        "adj_list = []\n",
        "noun_list = []\n",
        "adverb_list = []\n",
        "verb_list = []\n",
        "other_pos_list = []\n",
        "prop_noun_list = []\n",
        "\n",
        "for sample in review_sample:\n",
        "  review_doc = nlp(sample)\n",
        "\n",
        "# Break those into sentences\n",
        "  print('----')\n",
        "  for sentence in review_doc.sents:\n",
        "    print(sentence.text)\n",
        "\n",
        "\n",
        "# Find the part of speech\n",
        "  print('----')\n",
        "\n",
        "  tokens_list = []\n",
        "  for token in review_doc:\n",
        "    token_dict = {}\n",
        "    token_dict['text'] = token.text\n",
        "    token_dict['lemma'] = token.lemma_\n",
        "    token_dict['part_of_speech'] = token.pos_\n",
        "    token_dict['dependency'] = token.dep_\n",
        "    token_dict['shape'] = token.shape_\n",
        "    token_dict['alphabet?'] = token.is_alpha\n",
        "    token_dict['stop_word'] = token.is_stop\n",
        "    token_dict['punctuation'] = token.is_punct\n",
        "    token_dict['digit'] = token.is_digit\n",
        "    token_dict['language'] = token.lang_\n",
        "    token_dict['prefix'] = token.prefix_\n",
        "    token_dict['sentiment'] = token.sentiment\n",
        "    token_dict['currency'] = token.is_currency\n",
        "\n",
        "    tokens_list.append(token_dict)\n",
        " \n",
        "    if token.is_stop:\n",
        "      stop_word_list.append(token)\n",
        "    if token.is_punct:\n",
        "      punctuation_list.append(token)\n",
        "    if token.lang_ != 'en':\n",
        "      non_english_list.append(token)\n",
        "    if token.pos_ == 'DET':\n",
        "      det_list.append(token)\n",
        "    elif token.pos_ == 'ADJ':\n",
        "      adj_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'NOUN':\n",
        "      noun_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'ADV':\n",
        "      adverb_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'VERB':\n",
        "      verb_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'PROPN':\n",
        "      prop_noun_list.append(token.lemma_)\n",
        "    else:\n",
        "      other_pos_list.append(token)\n",
        "\n",
        "    df_token = pd.concat([df_token, pd.DataFrame(tokens_list)],axis=0)\n",
        "\n",
        "print(\"Noun List: {}\".format(noun_list))\n",
        "print(\"Proper Noun List: {}\".format(prop_noun_list))\n",
        "print(\"Adjective List: {}\".format(adj_list))\n",
        "print(\"Verb List: {}\".format(verb_list))\n",
        "print(\"Adverb List: {}\".format(adverb_list))\n",
        "print(\"Det List: {}\".format(det_list))\n",
        "print(\"Other POS List: {}\".format(other_pos_list))\n",
        "print(\"Non-English: {}\".format(non_english_list))\n",
        "print(\"Punctuations: {}\".format(punctuation_list))\n",
        "print(\"Stop Words: {}\".format(stop_word_list))\n",
        "\n",
        "df_token"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "First.\n",
            "I've had these before\n",
            "and they've changed the aioli sauce.\n",
            "The sauce was the best.\n",
            "Disappointing. \n",
            "\n",
            "\n",
            "Oh, and presentation was fine, but my photo doesn't do it justice because I shove food into my mouth before remembering to take photos . \n",
            "\n",
            "\n",
            "Imagine two perfectly fried egg rolls filled with mac and cheese and a container of mediocre sauce. \n",
            "\n",
            "#roosterredemption\n",
            "----\n",
            "----\n",
            "Thoroughly enjoyed the Glow Bowl!\n",
            "Unfortunately I had almost finished when I remembered that I had wanted to take a photo of it!\n",
            "ðŸ™ˆWould say that Iâ€™d order it again, but there are so many delicious-sounding menu items, that Iâ€™ll probably try something new!\n",
            "ðŸ˜‰\n",
            "Also had the Tutti Frutti juice which was really good!\n",
            "On the way out I picked up some snacks to try.\n",
            "As Iâ€™m saving these I was able to photograph them!\n",
            "----\n",
            "----\n",
            "This dish was beautifully presented, with a wide selection of tastes like sweet potato, baby spinach, spicy chickpeas, avocado, roasted carrots, radish, sesame seeds and a tahini dressing.\n",
            "----\n",
            "----\n",
            "Delicious and smokey!\n",
            "Fresh ingredients and definitely worth the detour stop!\n",
            "#ashers #ashersfarmsanctuary #lexishealthyeatery\n",
            "----\n",
            "----\n",
            "Delicious buffalo cauliflower wrap #lexishealthyeatery #ashers\n",
            "----\n",
            "Noun List: ['aioli', 'sauce', 'sauce', 'presentation', 'photo', 'justice', 'food', 'mouth', 'photo', 'egg', 'roll', 'mac', 'cheese', 'container', 'sauce', 'roosterredemption', 'photo', 'menu', 'item', 'something', 'juice', 'way', 'snack', 'dish', 'selection', 'taste', 'potato', 'baby', 'spinach', 'chickpea', 'avocado', 'carrot', 'radish', 'sesame', 'seed', 'tahini', 'dressing', 'ingredient', 'detour', 'stop', 'asher', '#', 'lexishealthyeatery', 'buffalo', 'cauliflower', 'wrap', 'lexishealthyeatery', 'asher']\n",
            "Proper Noun List: ['Glow', 'Bowl', 'Tutti', 'Frutti']\n",
            "Adjective List: ['good', 'disappointing', 'fine', 'mediocre', 'many', 'delicious', 'new', 'good', 'able', 'wide', 'sweet', 'spicy', 'roasted', 'delicious', 'smokey', 'fresh', 'worth', 'ashersfarmsanctuary', 'delicious']\n",
            "Verb List: ['have', 'have', 'have', 'change', 'be', 'be', 'do', 'do', 'shove', 'remember', 'take', 'imagine', 'fry', 'fill', 'enjoy', 'have', 'finish', 'remember', 'have', 'want', 'take', 'ðŸ™ˆ', 'Would', 'say', 'order', 'be', 'sound', 'try', 'have', 'be', 'pick', 'try', 'be', 'save', 'be', 'photograph', 'be', 'present']\n",
            "Adverb List: ['first', 'before', 'not', 'perfectly', 'thoroughly', 'unfortunately', 'almost', 'when', 'again', 'there', 'so', 'probably', 'also', 'really', 'out', 'beautifully', 'definitely']\n",
            "Det List: [these, the, The, the, my, my, a, the, a, the, which, the, some, these, This, a, a, the]\n",
            "Other POS List: [., I, and, they, ., ., ., \n",
            "\n",
            ", Oh, ,, and, ,, but, it, because, I, into, before, to, ., \n",
            "\n",
            ", two, with, and, and, of, ., \n",
            ", #, !, I, I, that, I, to, of, it, !, that, I, â€™d, it, ,, but, -, ,, that, I, â€™ll, !, ðŸ˜‰, !, On, I, up, to, ., As, I, I, to, them, !, ,, with, of, like, ,, ,, ,, ,, ,, ,, and, ., and, !, and, !, #, #, #, #]\n",
            "Non-English: []\n",
            "Punctuations: [., ., ., ., ,, ,, ., ., #, !, !, ,, -, ,, !, !, ., !, ,, ,, ,, ,, ,, ,, ,, ., !, !, #, #, #, #, #]\n",
            "Stop Words: [First, I, 've, had, these, before, and, they, 've, the, The, was, the, and, was, but, my, does, n't, do, it, because, I, into, my, before, to, take, two, with, and, and, a, of, the, I, had, almost, when, I, that, I, had, to, take, a, of, it, Would, say, that, I, it, again, but, there, are, so, many, that, I, something, Also, had, the, which, was, really, On, the, out, I, up, some, to, As, I, these, I, was, to, them, This, was, with, a, of, and, a, and, and, the]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>part_of_speech</th>\n",
              "      <th>dependency</th>\n",
              "      <th>shape</th>\n",
              "      <th>alphabet?</th>\n",
              "      <th>stop_word</th>\n",
              "      <th>punctuation</th>\n",
              "      <th>digit</th>\n",
              "      <th>language</th>\n",
              "      <th>prefix</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>currency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>First</td>\n",
              "      <td>first</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>F</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>First</td>\n",
              "      <td>first</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>F</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punct</td>\n",
              "      <td>.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>First</td>\n",
              "      <td>first</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>F</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punct</td>\n",
              "      <td>.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wrap</td>\n",
              "      <td>wrap</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>w</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#</td>\n",
              "      <td>#</td>\n",
              "      <td>SYM</td>\n",
              "      <td>nmod</td>\n",
              "      <td>#</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>#</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lexishealthyeatery</td>\n",
              "      <td>lexishealthyeatery</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>compound</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>l</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#</td>\n",
              "      <td>#</td>\n",
              "      <td>SYM</td>\n",
              "      <td>nmod</td>\n",
              "      <td>#</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>#</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ashers</td>\n",
              "      <td>asher</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>dobj</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7762 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  text               lemma  ... sentiment currency\n",
              "0                First               first  ...       0.0    False\n",
              "0                First               first  ...       0.0    False\n",
              "1                    .                   .  ...       0.0    False\n",
              "0                First               first  ...       0.0    False\n",
              "1                    .                   .  ...       0.0    False\n",
              "..                 ...                 ...  ...       ...      ...\n",
              "3                 wrap                wrap  ...       0.0    False\n",
              "4                    #                   #  ...       0.0    False\n",
              "5   lexishealthyeatery  lexishealthyeatery  ...       0.0    False\n",
              "6                    #                   #  ...       0.0    False\n",
              "7               ashers               asher  ...       0.0    False\n",
              "\n",
              "[7762 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkKogRNDtYMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the English language class\n",
        "from spacy.lang.en import English\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UqzResNSuEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2dba8885-1f8d-411f-a8f3-d58b5d6dacac"
      },
      "source": [
        "similarity_list = []\n",
        "for token1 in review_doc:\n",
        "  for token2 in review_doc:\n",
        "    sim_dict = {}\n",
        "    sim_dict['word_1'] = token1.text\n",
        "    sim_dict['word_2'] = token2.text\n",
        "\n",
        "    try:\n",
        "      sim_dict['similarity'] = token1.similarity(token2)\n",
        "    except:\n",
        "      print('error')\n",
        "\n",
        "\n",
        "    similarity_list.append(sim_dict)\n",
        "\n",
        "df_similarity = pd.DataFrame(similarity_list)\\\n",
        ".query('similarity < 0.9999')\\\n",
        ".sort_values(['similarity'],ascending=False)\n",
        "df_similarity"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_1</th>\n",
              "      <th>word_2</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>broc</td>\n",
              "      <td>cauli</td>\n",
              "      <td>0.649460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>cauli</td>\n",
              "      <td>broc</td>\n",
              "      <td>0.649460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>and</td>\n",
              "      <td>for</td>\n",
              "      <td>0.570359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>for</td>\n",
              "      <td>and</td>\n",
              "      <td>0.570359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>love</td>\n",
              "      <td>!</td>\n",
              "      <td>0.450742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>x</td>\n",
              "      <td>broc</td>\n",
              "      <td>-0.147135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>cauli</td>\n",
              "      <td>for</td>\n",
              "      <td>-0.182374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>for</td>\n",
              "      <td>cauli</td>\n",
              "      <td>-0.182374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>broc</td>\n",
              "      <td>for</td>\n",
              "      <td>-0.194480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>for</td>\n",
              "      <td>broc</td>\n",
              "      <td>-0.194480</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>202 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    word_1 word_2  similarity\n",
              "194   broc  cauli    0.649460\n",
              "222  cauli   broc    0.649460\n",
              "198    and    for    0.570359\n",
              "58     for    and    0.570359\n",
              "5     love      !    0.450742\n",
              "..     ...    ...         ...\n",
              "177      x   broc   -0.147135\n",
              "213  cauli    for   -0.182374\n",
              "59     for  cauli   -0.182374\n",
              "183   broc    for   -0.194480\n",
              "57     for   broc   -0.194480\n",
              "\n",
              "[202 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf2qN5p6-lyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "c56d4f2e-4c1d-4c24-e417-96b467b907d7"
      },
      "source": [
        "displacy.render(nlp(\"Seitan hot dog was really good and flavourful with a good bounce that you want in a hot dog.\"),'dep',True,0,jupyter=True)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"02727b9a385a49b095fc8663f8a0aae3-0\" class=\"displacy\" width=\"3375\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Seitan</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">hot</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">dog</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">was</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">really</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">good</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">flavourful</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">with</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">good</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">bounce</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">that</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">want</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">hot</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">dog.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-6\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1265.0,354.0 L1273.0,342.0 1257.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-7\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 1970.0,89.5 1970.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,354.0 L1978.0,342.0 1962.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-11\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,177.0 2490.0,177.0 2490.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,354.0 L2162,342.0 2178,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-12\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,264.5 2485.0,264.5 2485.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,354.0 L2337,342.0 2353,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-13\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,89.5 2495.0,89.5 2495.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2495.0,354.0 L2503.0,342.0 2487.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-14\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,264.5 2660.0,264.5 2660.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2660.0,354.0 L2668.0,342.0 2652.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-15\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,177.0 3190.0,177.0 3190.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-16\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,264.5 3185.0,264.5 3185.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,354.0 L3037,342.0 3053,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-02727b9a385a49b095fc8663f8a0aae3-0-17\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,89.5 3195.0,89.5 3195.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-02727b9a385a49b095fc8663f8a0aae3-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3195.0,354.0 L3203.0,342.0 3187.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>\n",
              "</figure>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN_3PnukkSab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.matcher import Matcher"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9uOfdy-AFH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEvT5QW0Ak7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "propn_adj_noun_pattern = [{'POS': 'PROPN'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}]\n",
        "adj_noun_pattern = [{'POS': 'ADJ'}, {'POS': 'NOUN'}]\n",
        "# Write a pattern for Vegan Chicken\n",
        "pattern_vegan_chicken = [{\"TEXT\": \"vegan\"}, {\"TEXT\": \"chicken\"}]\n",
        "\n",
        "# Write a pattern for ice cream\n",
        "pattern_ice_cream = [{\"TEXT\": \"ice\"}, {\"TEXT\": \"cream\"}]\n",
        "pattern_laksa = [{\"TEXT\": \"laksa\"}]\n",
        "pattern_pizza = [{\"TEXT\": \"pizza\"}]\n",
        "\n",
        "# Add the pattern to the matcher and apply the matcher to the doc\n",
        "matcher.add(\"propn_adj_noun\", None, propn_adj_noun_pattern)\n",
        "matcher.add(\"adj_noun\", None, adj_noun_pattern)\n",
        "matcher.add(\"vegan_chicken\", None, pattern_vegan_chicken)\n",
        "matcher.add(\"ice_cream\", None, pattern_ice_cream)\n",
        "matcher.add(\"laksa\", None, pattern_laksa)\n",
        "matcher.add(\"pizza\", None, pattern_pizza)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MG8YReFAKAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "245df02d-f95a-46d4-870f-7f7b55ce98f5"
      },
      "source": [
        "sentence1 = \"Seitan hot dog was really good and flavourful with a good bounce that you want in a hot dog.\"\n",
        "sentence2 = \"Vegan risotto was tasty\"\n",
        "\n",
        "sent_list = [sentence1, sentence2]\n",
        "\n",
        "for sentence in sent_list:\n",
        "  matches = matcher(nlp(sentence))\n",
        "  print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Iterate over the matches and print the span text\n",
        "  for match_id, start, end in matches:\n",
        "    print(\"Match found:\", nlp(sentence)[start:end].text)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total matches found: 1\n",
            "Match found: Seitan hot dog\n",
            "Total matches found: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fax1QyGNKuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "9160b750-7299-4c35-fb04-457c290ee34d"
      },
      "source": [
        "doc = nlp(\"A phrase with another phrase occurs.\")\n",
        "len(doc.noun_chunks_)\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-7e87db4b135a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A phrase with another phrase occurs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'noun_chunks_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG9omGQ7NUXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59bb78ec-7f41-4ce8-daf5-e5e77451b46a"
      },
      "source": [
        "list(nlp(sentence1).noun_chunks)\n",
        "list(nlp(sentence2).noun_chunks)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Seitan hot dog, a good bounce, you, a hot dog]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Vegan risotto]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Cr7uDwNSBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert chunks[0].text == \"A phrase\"\n",
        "assert chunks[1].text == \"another phrase\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvkUABhHIcEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "4e9712dc-ccfc-4e3f-cc83-ebab30c68822"
      },
      "source": [
        "review_text.info()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56156 entries, 0 to 56155\n",
            "Data columns (total 2 columns):\n",
            "_id     56156 non-null object\n",
            "text    56155 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 877.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQqc76WCi5FB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "8419e685-7eb2-4737-b0c1-1742c7978fb6"
      },
      "source": [
        "# Select a random review from the corpus\n",
        "check = random.randint(0,20000)\n",
        "review_sample = review_text['text'][check:check+5]\n",
        "#print(review_sample)\n",
        "\n",
        "# convert that into nlp\n",
        "\n",
        "\n",
        "noun_chunks_list = []\n",
        "\n",
        "for sample in review_sample:\n",
        "  review_doc = nlp(sample)\n",
        "  if len(review_doc.noun_chunks)\n",
        "  noun_chunks_list.append(list(review_doc.noun_chunks))\n",
        "  for sentence in review_doc.sents:\n",
        "    print(sentence.text)  \n",
        "\n",
        "noun_chunks_list"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is my absolute favourite veggie burger.\n",
            "Plus they have veg gravy!\n",
            "This vegan Buddhist restaurant is entirely staffed by volunteers and has no English menu.\n",
            "Iâ€™m a big fan of taro\n",
            "so I liked this dish, but it wasnâ€™t anything special.\n",
            "This vegan Buddhist restaurant is entirely staffed by volunteers and has no English menu.\n",
            "This dish was alright, but doesnâ€™t have a lot of flavours â€” kind of bland (which I find is common in some Buddhist restaurants).\n",
            "The tofu is liquidy which is fine, but not so pleasant when the food gets cold.\n",
            "This vegan Buddhist restaurant is entirely staffed by volunteers and has no English menu.\n",
            "These are kind of boring and bland â€” mostly flour with very few veggies.\n",
            "We asked for a dipping sauce and they brought the chinese spicy fermented bean sauce which I really donâ€™t like!\n",
            "This vegan Buddhist restaurant is entirely staffed by volunteers and has no English menu.\n",
            "A big plate of Choi sum for a decent price.\n",
            "It doesnâ€™t come with any dipping sauce\n",
            "so itâ€™s a bit boring.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[my absolute favourite veggie burger, they, veg gravy],\n",
              " [This vegan Buddhist restaurant,\n",
              "  volunteers,\n",
              "  no English menu,\n",
              "  I,\n",
              "  a big fan,\n",
              "  taro,\n",
              "  I,\n",
              "  this dish,\n",
              "  it,\n",
              "  anything],\n",
              " [This vegan Buddhist restaurant,\n",
              "  volunteers,\n",
              "  no English menu,\n",
              "  This dish,\n",
              "  a lot,\n",
              "  flavours,\n",
              "  I,\n",
              "  some Buddhist restaurants,\n",
              "  The tofu,\n",
              "  the food],\n",
              " [This vegan Buddhist restaurant,\n",
              "  volunteers,\n",
              "  no English menu,\n",
              "  kind of boring and bland â€” mostly flour,\n",
              "  very few veggies,\n",
              "  We,\n",
              "  a dipping sauce,\n",
              "  they,\n",
              "  the chinese spicy fermented bean sauce,\n",
              "  I],\n",
              " [This vegan Buddhist restaurant,\n",
              "  volunteers,\n",
              "  no English menu,\n",
              "  A big plate,\n",
              "  Choi,\n",
              "  a decent price,\n",
              "  It,\n",
              "  any dipping sauce,\n",
              "  it]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCqM4_80OrZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}