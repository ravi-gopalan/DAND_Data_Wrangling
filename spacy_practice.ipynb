{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_practice.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-gopalan/DAND_Data_Wrangling/blob/master/spacy_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXazOFp8iz_",
        "colab_type": "code",
        "outputId": "b30f5a6a-7111-4493-bbda-0ef7d49b01fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHFfNrsC8zKG",
        "colab_type": "code",
        "outputId": "7fc7ce0e-7bf9-4b51-9963-c7e4228f10ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/gdrive/My Drive/abv_reviews'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/abv_reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKXwPwMY86KN",
        "colab_type": "code",
        "outputId": "044b0c34-0468-4c38-ed5a-4c671e28be6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/  \u001b[01;34mpending_images\u001b[0m/  reviews_text.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ABgn0J8niK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0OtpPq79PoE",
        "colab_type": "code",
        "outputId": "0da1cebd-a5c0-450f-8909-6e8a87266704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import spacy\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "import en_core_web_lg\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "# Import the English language class\n",
        "from spacy.lang.en import English"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz3d_Y9l5tzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "db18fb79-96ab-40e7-d8ac-8c230fc3a60d"
      },
      "source": [
        "!pip install spacymoji\n",
        "from spacymoji import Emoji"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacymoji\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/42/b4460030eb06504451973609ab8a95b8c0106090aca7a4d657baf9b2611d/spacymoji-2.0.0-py3-none-any.whl\n",
            "Collecting emoji<1.0.0,>=0.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.0.0,>=2.1.3 in /usr/local/lib/python3.6/dist-packages (from spacymoji) (2.1.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.4.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.9.6)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (7.0.8)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (2.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (2.21.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (1.17.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy<3.0.0,>=2.1.3->spacymoji) (4.28.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (1.24.3)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42175 sha256=e7e2ad5967a844e71573e57df2cf7acddbe20fcfaa1b14829b1f04a9965bfc3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, spacymoji\n",
            "Successfully installed emoji-0.5.4 spacymoji-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in_zzznz9hpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg', disable = ['ner'])\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dlNGbSOAQN6",
        "colab_type": "code",
        "outputId": "054b9496-8053-4674-9b7c-9dad4e50a52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "df_review = pd.read_csv('reviews_text.csv')\n",
        "df_review.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56156 entries, 0 to 56155\n",
            "Data columns (total 36 columns):\n",
            "Unnamed: 0           56156 non-null int64\n",
            "_id                  56156 non-null object\n",
            "updatedAt            56156 non-null object\n",
            "createdAt            56156 non-null object\n",
            "originality          56156 non-null int64\n",
            "value                56156 non-null int64\n",
            "nutrition            56156 non-null int64\n",
            "presentation         56156 non-null int64\n",
            "taste                56156 non-null int64\n",
            "text                 56155 non-null object\n",
            "dish                 56156 non-null object\n",
            "type                 56156 non-null object\n",
            "isPublished          5885 non-null object\n",
            "user                 56156 non-null object\n",
            "restaurant           56156 non-null object\n",
            "images               56156 non-null object\n",
            "likes                56156 non-null object\n",
            "__v                  56156 non-null int64\n",
            "comments             56156 non-null object\n",
            "likesCount           56156 non-null int64\n",
            "tags                 56156 non-null object\n",
            "country              55340 non-null object\n",
            "commentsCount        56155 non-null float64\n",
            "overall              56156 non-null float64\n",
            "rating               56156 non-null object\n",
            "isProduct            22192 non-null object\n",
            "status               56156 non-null object\n",
            "textTags             56156 non-null object\n",
            "isPoked              48520 non-null object\n",
            "platform             38124 non-null object\n",
            "moderatedAt          18814 non-null object\n",
            "moderator            18814 non-null object\n",
            "brand                64 non-null object\n",
            "product              64 non-null object\n",
            "feedback             4512 non-null object\n",
            "moderationReasons    6915 non-null object\n",
            "dtypes: float64(2), int64(8), object(26)\n",
            "memory usage: 15.4+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (12,25,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7q6tGZ6DKRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "144897e4-6519-40eb-c631-f5190351b495"
      },
      "source": [
        "review_text = df_review[['_id','text']]\n",
        "review_text.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59e599911747c90004ba8586</td>\n",
              "      <td>Burger joint offers a wide range of cheeseburg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59ff122b8b04fd0004df6c78</td>\n",
              "      <td>It was really good. The mushroom broth was esp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5dc251e552e7e90020b6adfb</td>\n",
              "      <td>$8.90 for sesame rice, mushroom rendang, curry...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5d35cf4049745d0004c68de3</td>\n",
              "      <td>2 mains + 1 green rice bento from greendot. Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5d304e9264f5e5000423b75b</td>\n",
              "      <td>The lion mane mushroom rendang is so delicious...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id                                               text\n",
              "0  59e599911747c90004ba8586  Burger joint offers a wide range of cheeseburg...\n",
              "1  59ff122b8b04fd0004df6c78  It was really good. The mushroom broth was esp...\n",
              "2  5dc251e552e7e90020b6adfb  $8.90 for sesame rice, mushroom rendang, curry...\n",
              "3  5d35cf4049745d0004c68de3  2 mains + 1 green rice bento from greendot. Re...\n",
              "4  5d304e9264f5e5000423b75b  The lion mane mushroom rendang is so delicious..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeuDXFruu7-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine the # and tag to form hashtag\n",
        "\n",
        "matcher.add('HASHTAG', None, [{'ORTH': '#'}, {'IS_ASCII': True}])\n",
        "\n",
        "doc = nlp('This is a #sentence. Here is another #hashtag. #The #End.')\n",
        "matches = matcher(doc)\n",
        "hashtags = []\n",
        "for match_id, start, end in matches:\n",
        "    hashtags.append(doc[start:end])\n",
        "\n",
        "for span in hashtags:\n",
        "    span.merge()\n",
        "\n",
        "print([t.text for t in doc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD6MKsGmTq1T",
        "colab_type": "code",
        "outputId": "1456f472-6cda-48f9-ddc9-d50abfba8640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Select a random review from the corpus\n",
        "check = random.randint(0,20000)\n",
        "review_sample = review_text['text'][check:check+5]\n",
        "#print(review_sample)\n",
        "\n",
        "# convert that into nlp\n",
        "df_token = pd.DataFrame()\n",
        "\n",
        "stop_word_list = []\n",
        "punctuation_list = []\n",
        "non_english_list = []\n",
        "det_list = []\n",
        "adj_list = []\n",
        "noun_list = []\n",
        "adverb_list = []\n",
        "verb_list = []\n",
        "other_pos_list = []\n",
        "prop_noun_list = []\n",
        "hashtags = []\n",
        "\n",
        "for sample in review_sample:\n",
        "  review_doc = nlp(sample)\n",
        "\n",
        "# Break those into sentences\n",
        "  print('----')\n",
        "  for sentence in review_doc.sents:\n",
        "    print(sentence.text)\n",
        "\n",
        "  matches = matcher(review_doc)\n",
        "\n",
        "  for match_id, start, end in matches:\n",
        "    hashtags.append(review_doc[start:end])\n",
        "\n",
        "  for span in hashtags:\n",
        "    span.merge()\n",
        "\n",
        "\n",
        "# Find the part of speech\n",
        "  print('----')\n",
        "\n",
        "  tokens_list = []\n",
        "  for token in review_doc:\n",
        "    token_dict = {}\n",
        "    token_dict['text'] = token.text\n",
        "    token_dict['lemma'] = token.lemma_\n",
        "    token_dict['part_of_speech'] = token.pos_\n",
        "    token_dict['dependency'] = token.dep_\n",
        "    token_dict['shape'] = token.shape_\n",
        "    token_dict['alphabet?'] = token.is_alpha\n",
        "    token_dict['stop_word'] = token.is_stop\n",
        "    token_dict['punctuation'] = token.is_punct\n",
        "    token_dict['digit'] = token.is_digit\n",
        "    token_dict['language'] = token.lang_\n",
        "    token_dict['prefix'] = token.prefix_\n",
        "    token_dict['sentiment'] = token.sentiment\n",
        "    token_dict['currency'] = token.is_currency\n",
        "\n",
        "    tokens_list.append(token_dict)\n",
        " \n",
        "    if token.is_stop:\n",
        "      stop_word_list.append(token)\n",
        "    if token.is_punct:\n",
        "      punctuation_list.append(token)\n",
        "    if token.lang_ != 'en':\n",
        "      non_english_list.append(token)\n",
        "    if token.pos_ == 'DET':\n",
        "      det_list.append(token)\n",
        "    elif token.pos_ == 'ADJ':\n",
        "      adj_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'NOUN':\n",
        "      noun_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'ADV':\n",
        "      adverb_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'VERB':\n",
        "      verb_list.append(token.lemma_)\n",
        "    elif token.pos_ == 'PROPN':\n",
        "      prop_noun_list.append(token.lemma_)\n",
        "    else:\n",
        "      other_pos_list.append(token)\n",
        "\n",
        "    df_token = pd.concat([df_token, pd.DataFrame(tokens_list)],axis=0)\n",
        "\n",
        "print(\"Noun List: {}\".format(set(noun_list)))\n",
        "print(\"Proper Noun List: {}\".format(set(prop_noun_list)))\n",
        "print(\"Adjective List: {}\".format(set(adj_list)))\n",
        "print(\"Verb List: {}\".format(set(verb_list)))\n",
        "print(\"Adverb List: {}\".format(set(adverb_list)))\n",
        "print(\"Det List: {}\".format(set(det_list)))\n",
        "print(\"Other POS List: {}\".format(set(other_pos_list)))\n",
        "print(\"Non-English: {}\".format(set(non_english_list)))\n",
        "print(\"Punctuations: {}\".format(set(punctuation_list)))\n",
        "print(\"Stop Words: {}\".format(set(stop_word_list)))\n",
        "\n",
        "df_token"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "One of the best if not the best green mango salad we have had.\n",
            "Just the right amount of spice and really fresh and well made.\n",
            "----\n",
            "----\n",
            "We expected this to follow the same standards as other dishes but this dish could be a lot better.\n",
            "Not too spicy and just like any other place this dish was so so\n",
            "----\n",
            "----\n",
            "This Korean Mexican fushion restaurant in Central is a tiny place to grab a cheap lunch.\n",
            "You can order the eggplant filling as a burrito, tacos or salad.\n",
            "It’s vegetarian but if you omit the sour cream and cheese, it’s vegan.\n",
            "The tacos are pretty big and come with large chunks of eggplant, chillies, fresh veggies, sesame seeds, and ginger sauce.\n",
            "----\n",
            "----\n",
            "This cafe is part of a guest house in Chiang Mai.\n",
            "It has tons of vegan and veggie options, including Thai and Western food.\n",
            "This curry was fresh, delicious, and not too spicy.\n",
            "Order with brown rice!\n",
            "----\n",
            "----\n",
            "Pennywort is apparently a superfood in Asia, which I’d never tried before.\n",
            "This salad was fresh and delicious.\n",
            "The place itself is a social enterprise, where the cafe profits benefit refugee families in Thailand and support a children’s learning centre.\n",
            "You can also purchase used books, used clothing, crafts made by the children, kombucha tea, and other gift items in the cafe which go towards the learning centre.\n",
            "----\n",
            "Noun List: {'standard', 'ton', 'restaurant', 'child', 'rice', 'mango', 'lunch', 'family', 'vegan', 'order', 'spice', 'item', 'sauce', 'cafe', 'superfood', 'fushion', 'part', 'filling', 'craft', 'salad', 'cheese', 'option', 'guest', 'centre', 'house', 'burrito', 'veggie', 'ginger', 'seed', 'tea', 'profit', 'enterprise', 'gift', 'lot', 'clothing', 'taco', 'sesame', 'dish', 'eggplant', 'chilli', 'kombucha', 'curry', 'food', 'book', 'chunk', 'learning', 'refugee', 'cream', 'amount', 'place'}\n",
            "Proper Noun List: {'Thailand', 'Mexican', 'Chiang', 'Mai', 'Asia', 'Central', 'Pennywort', 'Thai'}\n",
            "Adjective List: {'well', 'good', 'vegan', 'sour', 'right', 'other', 'green', 'big', 'veggie', 'delicious', 'vegetarian', 'same', 'western', 'korean', 'tiny', 'large', 'fresh', 'social', 'cheap', 'spicy', 'brown'}\n",
            "Verb List: {'support', 'benefit', 'could', 'include', 'follow', 'omit', 'use', 'purchase', 'grab', 'can', 'be', 'go', 'expect', 'order', '’', 'come', 'try', 'make', 'have'}\n",
            "Adverb List: {'so', 'just', 'before', 'apparently', 'well', 'where', 'too', 'never', 'also', 'not', 'pretty', 'really'}\n",
            "Det List: {the, a, which, the, this, a, The, a, the, the, the, the, the, This, a, the, the, The, a, the, This, this, this, which, This, a, a, a, any, This}\n",
            "Other POS List: {., as, ., ,, or, ., of, You, ,, of, ., and, if, and, ,, We, and, and, and, towards, It, ., ,, and, I, and, ., in, in, ., ., ., in, if, but, itself, and, we, as, ,, One, ., ,, ,, ’d, ’s, and, with, in, ,, You, ., like, ., it, and, ,, with, of, to, ,, ,, ,, !, and, but, in, ,, of, you, by, and, of, ., It, ., ,, to, ,}\n",
            "Non-English: set()\n",
            "Punctuations: {., ., ,, ., ,, ., ,, ., ,, ., ., ., ., ,, ,, ., ,, ,, ., ., ,, ,, ,, ,, !, ., ., ,, ,, ,}\n",
            "Stop Words: {are, a, of, a, a, We, and, was, and, if, but, is, we, as, a, the, the, with, in, a, amount, it, of, can, but, which, is, This, same, a, too, so, the, or, used, of, You, this, and, other, and, the, and, and, and, the, in, Just, can, This, other, is, really, The, You, not, made, has, to, never, this, too, of, was, of, the, This, as, go, was, which, The, so, It, the, in, before, just, itself, and, well, and, have, also, could, the, and, This, this, made, you, by, It, used, to, the, if, part, the, other, towards, I, in, One, is, Not, with, and, in, had, a, and, be, a, any, not, where}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>part_of_speech</th>\n",
              "      <th>dependency</th>\n",
              "      <th>shape</th>\n",
              "      <th>alphabet?</th>\n",
              "      <th>stop_word</th>\n",
              "      <th>punctuation</th>\n",
              "      <th>digit</th>\n",
              "      <th>language</th>\n",
              "      <th>prefix</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>currency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One</td>\n",
              "      <td>one</td>\n",
              "      <td>NUM</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>Xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One</td>\n",
              "      <td>one</td>\n",
              "      <td>NUM</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>Xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>ADP</td>\n",
              "      <td>prep</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>o</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One</td>\n",
              "      <td>one</td>\n",
              "      <td>NUM</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>Xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>ADP</td>\n",
              "      <td>prep</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>o</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>towards</td>\n",
              "      <td>towards</td>\n",
              "      <td>ADP</td>\n",
              "      <td>prep</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>t</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>t</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>learning</td>\n",
              "      <td>learning</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>compound</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>l</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>centre</td>\n",
              "      <td>centre</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>pobj</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>c</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punct</td>\n",
              "      <td>.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7932 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        text     lemma part_of_speech  ... prefix sentiment  currency\n",
              "0        One       one            NUM  ...      O       0.0     False\n",
              "0        One       one            NUM  ...      O       0.0     False\n",
              "1         of        of            ADP  ...      o       0.0     False\n",
              "0        One       one            NUM  ...      O       0.0     False\n",
              "1         of        of            ADP  ...      o       0.0     False\n",
              "..       ...       ...            ...  ...    ...       ...       ...\n",
              "75   towards   towards            ADP  ...      t       0.0     False\n",
              "76       the       the            DET  ...      t       0.0     False\n",
              "77  learning  learning           NOUN  ...      l       0.0     False\n",
              "78    centre    centre           NOUN  ...      c       0.0     False\n",
              "79         .         .          PUNCT  ...      .       0.0     False\n",
              "\n",
              "[7932 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkKogRNDtYMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fff430a6-e164-4480-d49c-d4ee9b8ed377"
      },
      "source": [
        "hashtags\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UqzResNSuEE",
        "colab_type": "code",
        "outputId": "2dba8885-1f8d-411f-a8f3-d58b5d6dacac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "similarity_list = []\n",
        "for token1 in review_doc:\n",
        "  for token2 in review_doc:\n",
        "    sim_dict = {}\n",
        "    sim_dict['word_1'] = token1.text\n",
        "    sim_dict['word_2'] = token2.text\n",
        "\n",
        "    try:\n",
        "      sim_dict['similarity'] = token1.similarity(token2)\n",
        "    except:\n",
        "      print('error')\n",
        "\n",
        "\n",
        "    similarity_list.append(sim_dict)\n",
        "\n",
        "df_similarity = pd.DataFrame(similarity_list)\\\n",
        ".query('similarity < 0.9999')\\\n",
        ".sort_values(['similarity'],ascending=False)\n",
        "df_similarity"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_1</th>\n",
              "      <th>word_2</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>broc</td>\n",
              "      <td>cauli</td>\n",
              "      <td>0.649460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>cauli</td>\n",
              "      <td>broc</td>\n",
              "      <td>0.649460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>and</td>\n",
              "      <td>for</td>\n",
              "      <td>0.570359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>for</td>\n",
              "      <td>and</td>\n",
              "      <td>0.570359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>love</td>\n",
              "      <td>!</td>\n",
              "      <td>0.450742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>x</td>\n",
              "      <td>broc</td>\n",
              "      <td>-0.147135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>cauli</td>\n",
              "      <td>for</td>\n",
              "      <td>-0.182374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>for</td>\n",
              "      <td>cauli</td>\n",
              "      <td>-0.182374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>broc</td>\n",
              "      <td>for</td>\n",
              "      <td>-0.194480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>for</td>\n",
              "      <td>broc</td>\n",
              "      <td>-0.194480</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>202 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    word_1 word_2  similarity\n",
              "194   broc  cauli    0.649460\n",
              "222  cauli   broc    0.649460\n",
              "198    and    for    0.570359\n",
              "58     for    and    0.570359\n",
              "5     love      !    0.450742\n",
              "..     ...    ...         ...\n",
              "177      x   broc   -0.147135\n",
              "213  cauli    for   -0.182374\n",
              "59     for  cauli   -0.182374\n",
              "183   broc    for   -0.194480\n",
              "57     for   broc   -0.194480\n",
              "\n",
              "[202 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf2qN5p6-lyc",
        "colab_type": "code",
        "outputId": "c9187899-b906-4170-a092-eeb1858dcc45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "displacy.render(nlp(\"Seitan hot dog was really good and flavourful with a good bounce that you want in a hot dog.\"),'dep',True,0,jupyter=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6fc43bc370f4428f87f506da00206f4a-0\" class=\"displacy\" width=\"3375\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Seitan</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">hot</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">dog</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">was</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">really</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">good</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">flavourful</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">with</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">good</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">bounce</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">that</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">want</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">hot</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">dog.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-6\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1265.0,354.0 L1273.0,342.0 1257.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-7\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 1970.0,89.5 1970.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,354.0 L1978.0,342.0 1962.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-11\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,177.0 2490.0,177.0 2490.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,354.0 L2162,342.0 2178,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-12\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,264.5 2485.0,264.5 2485.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,354.0 L2337,342.0 2353,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-13\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,89.5 2495.0,89.5 2495.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2495.0,354.0 L2503.0,342.0 2487.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-14\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,264.5 2660.0,264.5 2660.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2660.0,354.0 L2668.0,342.0 2652.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-15\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,177.0 3190.0,177.0 3190.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-16\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,264.5 3185.0,264.5 3185.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,354.0 L3037,342.0 3053,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6fc43bc370f4428f87f506da00206f4a-0-17\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,89.5 3195.0,89.5 3195.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6fc43bc370f4428f87f506da00206f4a-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3195.0,354.0 L3203.0,342.0 3187.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>\n",
              "</figure>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN_3PnukkSab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9uOfdy-AFH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEvT5QW0Ak7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Write a pattern for Vegan Chicken\n",
        "pattern_vegan_chicken = [{\"TEXT\": \"vegan\"}, {\"TEXT\": \"chicken\"}]\n",
        "\n",
        "# Write a pattern for ice cream\n",
        "pattern_ice_cream = [{\"TEXT\": \"ice\"}, {\"TEXT\": \"cream\"}]\n",
        "pattern_laksa = [{\"TEXT\": \"laksa\"}]\n",
        "pattern_pizza = [{\"TEXT\": \"pizza\"}]\n",
        "\n",
        "# Add the pattern to the matcher and apply the matcher to the doc\n",
        "matcher.add('HASHTAG', None, [{'ORTH': '#'}, {'IS_ASCII': True}])\n",
        "matcher.add('hyphenated',None,[{'IS_ASCII': True},{'ORTH': '-'},{'IS_ASCII': True}])\n",
        "matcher.add(\"propn_adj_noun\", None, [{'POS': 'PROPN'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}])\n",
        "matcher.add(\"adj_noun\", None, [{'POS': 'NOUN'}, {'POS': 'NOUN'}])\n",
        "#matcher.add(\"vegan_chicken\", None, pattern_vegan_chicken)\n",
        "#matcher.add(\"ice_cream\", None, pattern_ice_cream)\n",
        "#matcher.add(\"laksa\", None, pattern_laksa)\n",
        "#matcher.add(\"pizza\", None, pattern_pizza)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MG8YReFAKAQ",
        "colab_type": "code",
        "outputId": "5b6b91be-d0a4-4e1b-e9d1-5166327a0006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "sentence1 = \"Seitan hot dog was really good and flavourful with a good bounce that you want in a hot dog.\"\n",
        "sentence2 = \"This burger is one of the reasons why non-vegans say vegan food tastes bad.\"\n",
        "\n",
        "sent_list = [sentence1, sentence2]\n",
        "\n",
        "for sentence in sent_list:\n",
        "  matches = matcher(nlp(sentence))\n",
        "  print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Iterate over the matches and print the span text\n",
        "  for match_id, start, end in matches:\n",
        "    print(\"Match found:\", nlp(sentence)[start:end].text)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total matches found: 1\n",
            "Match found: Seitan hot dog\n",
            "Total matches found: 2\n",
            "Match found: non-\n",
            "Match found: non-vegans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fax1QyGNKuf",
        "colab_type": "code",
        "outputId": "9160b750-7299-4c35-fb04-457c290ee34d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "doc = nlp(\"A phrase with another phrase occurs.\")\n",
        "len(doc.noun_chunks_)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-7e87db4b135a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A phrase with another phrase occurs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'noun_chunks_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG9omGQ7NUXr",
        "colab_type": "code",
        "outputId": "59bb78ec-7f41-4ce8-daf5-e5e77451b46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(nlp(sentence1).noun_chunks)\n",
        "list(nlp(sentence2).noun_chunks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Seitan hot dog, a good bounce, you, a hot dog]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Vegan risotto]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Cr7uDwNSBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert chunks[0].text == \"A phrase\"\n",
        "assert chunks[1].text == \"another phrase\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvkUABhHIcEJ",
        "colab_type": "code",
        "outputId": "4e9712dc-ccfc-4e3f-cc83-ebab30c68822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "review_text.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56156 entries, 0 to 56155\n",
            "Data columns (total 2 columns):\n",
            "_id     56156 non-null object\n",
            "text    56155 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 877.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQqc76WCi5FB",
        "colab_type": "code",
        "outputId": "cb632c9b-cacd-4fc5-f6b8-cecf11984cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Select a random review from the corpus\n",
        "check = random.randint(0,20000)\n",
        "review_sample = review_text['text'][check:check+100]\n",
        "#print(review_sample)\n",
        "\n",
        "\n",
        "\n",
        "matches_list = []\n",
        "\n",
        "for sample in review_sample:\n",
        "  review_doc = nlp(sample)\n",
        "  matches = matcher(review_doc)\n",
        "  print(len(matches), sample )\n",
        "\n",
        "# Iterate over the matches and print the span text\n",
        "  for match_id, start, end in matches:\n",
        "    matches_list.append(review_doc[start:end].text)\n",
        "\n",
        "\n",
        "matches_list"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 One of the best mooncakes I’ve tried so far :3 Nice taste of green tea & red bean although it’s on the sweeter side!\n",
            "4 Fresh red bean flavour and not too sweet. Classic combination done well. #sgeats #mooncake #redbean\n",
            "3 My favourite #mooncake in Singapore mainly because of the textures, umami and perfect balance between savoury and sweet. Tip: cut with a sharp knife not the butter knife 😂 #bestpicks\n",
            "4 My favourite locally made mooncake. The yolk is made of carrots I believe. It doesn’t taste like carrots at all. Very umami, has the texture of egg yolk and well salted. Contrasts well with the sweet lotus paste. #sgeats #mooncake\n",
            "2 Soy fanática de los Hor fun en general, pero estos no me gustaron mucho porque le pusieron unos ajíes que venían en vinagre y como que no combinaban con el sabor del plato😟\n",
            "0 The green chillies in this were quite essential. While it looks starchy, it's not too oily. Quite alright for a $4.50 lunch.\n",
            "0 I really enjoyed my Hor Fun. I added some extra “mock meat” onto it so that there was more stuff in my dish. For only $4.50 in total, it’s quite a good deal on the CBD area.\n",
            "4 Honestly the worst hor fun I’ve ever had. No wok hei at all and some parts of the fun tastes like plain chee Cheong fun. I really don’t like to criticize our local hawkers because I know they work hard, but this standard cannot la. The green chilli was more tasty than the dish itself. The tofu was also sourish means it’s gone slightly bad. Mummy yummy does this much better. Might give their caifan a try but this, #neveragain #sgeats #horfun\n",
            "0 Excellent \n",
            "Would highly recommend this restaurant, service was good and they were very accommodating\n",
            "1 Very good, with a good size portions. They have a English menu, with Vegan options as well\n",
            "0 So good! Perfectly fried. Even the thick ones are crispy.\n",
            "1 My first time having jackfruit. It was good, I am not generally a fan of fake meat but this was a good mix of being like meat but also just being a natural fruit with bbq sauce. The coleslaw on the sandwich added a lot\n",
            "0 “Savory Jackfruit Tossed In Our House BBQ On A Whole Wheat Bun With Pickles, Onion, And Sweet Slaw”. I thought it was very tasty. They could have shredded the jackfruit into smaller pieces, but overall it was a winner for me.\n",
            "1 The flavor was good, but you have to like coconut because it’s comes through strongly. I thought the texture was a little grainy but if you need a soft serve fix, it’s pretty good.\n",
            "0 Great as always. Love the vegan thousand island. Fries super fresh.\n",
            "2 Overall very filling but could have a little more flavor. It comes with the option of with or without tomato sauce. #vivavanderbilt\n",
            "1 This salad is a garden itself. The lettuce is fresh and crisp. It's very fulfilling even without added tofu. Sesame ginger dressing to go with it. Yum!\n",
            "4 This was absolutely delicious! The vanilla bean pastry cream was perfect, and obviously you can’t go wrong with chocolate icing!\n",
            "0 Really good! Custard had a great texture and flavors were great\n",
            "3 Vanilla bean cream filled donut with rich chocolate frosting. One of my absolute faves.\n",
            "2 So good! The raspberry curd filling was delicious! I’d definitely get this one again.\n",
            "2 Fresh raspberry curd with vanilla icing. Absolutely divine!\n",
            "1 Delicious apple fritter that is a little crispy on the outside and soft on the inside.\n",
            "1 Soft yummy long John with rich maple frosting and coconut on top.\n",
            "0 Perfect , feels very healthy and clean after eating ! Not heavy at all.\n",
            "0 Even though it is Fried it is not that oily and taste good\n",
            "4 When the craving strikes for comfort food, Sassafras has some delicious replacements for old favorites like Fried Scallops, Nashville Hot Chick-un, and Seitan Pastrami. #comfortfood #bostonvegan\n",
            "12 The Coco Berry Bowl from Pressed is one of my favorite smoothie bowls in the city. It’s made with maqui berry, açaí berry, assorted summer berries, almond butter, and housemade granola - and it’s a great breakfast option. 🥄 #smoothiebowl #pressed #veganboston\n",
            "6 When you’re looking to treat yourself, by Chloe’s ice cream push pops are next level. This Birthday Cake pop had chunks of funfetti cake inside! 🎉 🍰 #dessert #bychloe\n",
            "4 We came back to Fento for a 2nd time because it was that good! We stopped in for a quick bite in the late afternoon and went with the Vegan Nachos. They’re loaded with beans, salsa, and a delicious cashew crema sauce. You can get a full portion of the nachos or the smaller “nachitos.” 🌽 #nachos #veganamsterdam\n",
            "2 Following a great dinner, an outstanding dessert plate, all GF and vegan. The feuillete of the apple struddle was incredible, the crumble delicious and the chocolate short cakes were also one of a kind. Thumbs up!\n",
            "3 Super yummy! The dipping sauce was loaded/topped with peanuts, which I loved. #soberfish #Roosterredemption\n",
            "4 Omg I love this and would get again! #soberfish #Roosterredemption\n",
            "3 This is probably my favorite, basic sushi roll. Simple, but SO yummy. #soberfish #Roosterredemption\n",
            "5 Basic and delicious! #sushi #soberfish #roosterredemption\n",
            "2 This was ridiculously delicious. The mango was perfect! This has to be requested vegan though, or it will be prepared with dairy. #soberfish #Roosterredemption\n",
            "5 Gotta love that the folks at #avianodenver ran out of almond milk by 🕤 but they had #oatly barista which is amazing and made me a delicious mocha with dark chocolate! So delicious! #cherrycreek #coffee\n",
            "3 Described as: \"white bean, potato and garlic dip, seasonal relish, baguette.  *Vegan Available\" on the menu, it was a tasty appetizer of a warm baguette with basically white bean hummus with pepper and cucumber relish. Simple, but a nice vegan snack! Not something I would make a special trip to Forager for, but they have some other vegan options as well. #roosterredemption\n",
            "4 Described as \"BASIC PLACE\n",
            "sourdough, cucumbers, tomatoes, basil aioli, pickled radish, tempura sweet potatoes, capra nera goat cheese, microgreens  *Vegan Available\" we got the vegan. It was tasty other than they cooked it so long the crust of the bread was like a rock. With proper cooking time it would have been great! The fries were also delicious. #roosterredemption\n",
            "0 This dish was really good. The flavors of curry really came through with just a touch of heat. The vegetables were perfect and the tofu was great. I had two others try the dish and they both really liked it. @roosterredemption\n",
            "4 Penne with marinara and bell peppers and onions. The sauce has a strong bell pepper flavor, but it is possible to get just plain sauce and penne as a side. Overall filling and tasty. #vivavanderbilt\n",
            "2 Quite hard and plain. It’s basically what many people say “weird” vegan food is like. But t was very cheap\n",
            "#cookie #snack\n",
            "9 Birthday cake: vanilla cake and chocolate frosting; Cookie Dough: vanilla-chocolate chip cake and vanilla icing with cookie dough filling; gluten free! #vegout\n",
            "6 This tofu bowl came packed with a delicious quinoa base topped with perfectly herbed tofu chunks, savory watermelon radish, and cucumber slices. The pepperoncini added the perfect kick. This meal came with a cup of hot green tea and a delectable vegan brownie. #rpiveg\n",
            "3 I liked this burger a lot. It’s a black bean and corn party. I got it without tomato and chipotle mayo. The one drawback was that the party fell apart really easily which made it hard to eat. It can be made vegan! #vivavanderbilt\n",
            "2 This milkshake was delicious and great to go with a veggie burger! #vivavanderbilt\n",
            "4 This smoothie bowl was delicious! I got it without the protein powder since I don’t love the taste of protein powder. They also ran out of strawberries so I got blueberries on top instead which was still delicious! #vivavanderbilt\n",
            "4 One of the best mooncakes I've had omg. Didn't take a photo of the inside but it is basically LEGIT avocado puree and macadamia nuts 😍😍😍 not the usual lotus paste + salted egg yolk which can get quite sweet and heavy. Everyone loved this! I hope they sell this all year round so I can buy it again 😋\n",
            "8 I can't decide if this or the avocado one was better but they were clearly the 2 standouts of the mooncake party for sure!! This one reminded me of a mango mochi dessert I had at a Shanghainese restaurant a while ago that was AMAZINGGG. The inside is just cream and mango pieces. I think I can eat the whole thing by myself 😍#kele #mango\n",
            "1 This was so light and perfect. The icing was a nice sweet touch. Not to mention only $1.50. #roosterredemption\n",
            "1 An interesting dumpling flavour that tastes good and photographs well. Chewy and full of fresh veggies.\n",
            "2 The waiter actually called these “siu mai” so I guess they’re meant to imitate the famous fish dumplings. The fungus and veggies combined together gives it a nice presentation/texture and good flavour combination.\n",
            "0 These were quite chewy and reminded me of mochi. Yummy and not too sweet. The shredded coconut gives a nice texture.\n",
            "0 These were cute, small, tasty, and perfect for 2 people wanting to try a bunch of different dishes. The outside is light and flaky.\n",
            "0 These were more like dumplings than buns actually. A chewy outside with mushrooms on the inside.\n",
            "1 These are super chewy, with a glutinous outside and a bbq sauce inside, tasting like vegan char siu sauce with a few “meaty” pieces.\n",
            "0 Taro is one of my favourites, so I really enjoyed this dish. A soft cake that’s not too oily and doesn’t fall apart easily.\n",
            "0 These were great, although my friend told me they were too thick with bread to be traditional. Regardless, the outside was crispy, and the inside warm and fluffy, filled with delicious veggies.\n",
            "1 Never had a vegan version of this before, so really enjoyed it! Strong, black, sweet coffee with coconut whipped cream. It’s great that they don’t use plastic straws!\n",
            "4 I guess they don’t normally have these for sale, just around the mid-autumn festival. I really enjoyed this because it was light, unlike traditional mooncakes. The sweet potato filling was tasty without being too sweet and the ginger was strong and spicy.\n",
            "1 This is a half Rustler, half Fresh Veggie pizza with roasted garlic and artichoke heart added topped with Go veggie \"cheese\". Such a good combo for my partner and I to both get what we like on one pizza. We get this often and the staff is always so accommodating with this order, which is surely a pain in the butt lol.\n",
            "4 Forgot to take a photo before demolishing this fresh, vegan, well-balanced salad. Ingredients included avocado, kale, strawberries, blueberries, radish, cabbage, and tomatoes. Coupled with oat milk options for coffees and the other veg options here, Second Sip is a very vegan friendly spot! Best in Tai Hang imho.\n",
            "6 EDIT: they’ve switched to a non-vegan brioche bun so request sourdough instead. Great to find a whole-foods veggie burger that is vegan by default: portobello, houmous, cress, tomato, avocado, with a side salad. I added fries for $15. Very satisfying burger with fresh ingredients!\n",
            "3 They were testing out this item that day! Very homely although not exactly my type of #laksa (I like really strong and thick ones). Paste is made from scratch. No mock meat used but lots of smoky mushrooms 😍 #sgeats #noodles\n",
            "5 Asked them to fry it less because I had a heaty cough that day and they obliged 😂 very good quality tofu, smooth and tender with a bite. The sauce was refreshing and lemony. #tofu #sgeats\n",
            "3 From Healthy Vegetarian Food. The plain rice porridge had some brown rice and small tofu cubes mixed in, and had a texture similar to that of a well-blended smoothie. The boiled peanuts weren’t marinated I think but the sliced shiitake were and they were so good :3 The portion for $3 may be a bit small for some. Not oily at all! :)\n",
            "4 Loving hut does vegan catering and they do a good job! Everything was tasty and fresh. The rice had a lovely laksa leaf fragrance. #sgeats #vegancateringsg\n",
            "4 A bit dry but the #curry taste was awesome. Not exactly my kind of food but quite enjoyable overall. #sgeats #vegancateringsg\n",
            "2 Best veggie nuggets out there - love the sweet and sour meat too!\n",
            "2 I think that was the name? My fav mock meat of the spread, juicy with a good bite. #sgeats #vegancateringsg\n",
            "3 Pretty standard, good curry flavour with crisp skin. #sgeats #vegancateringsg\n",
            "2 the one at the Top. That was my fav dish of the whole catering! Cabbage, carrot, mushrooms well done, juicy and crisp. It was the first dish to be gone. I tried to go back for seconds but not much was left. #sgeats #vegancateringsg\n",
            "1 Penne with Alfredo sauce, zucchini, squash, carrots, and onions. #vivavanderbilt\n",
            "5 Not a fan of this sour cream, it's more like cream cheese in texture.  Used it in nachos #tofutti #hyvee #springfarmsanctuary\n",
            "0 So delicious. Flavorful and filling and beautiful. You gotta go here if you're in the area!!\n",
            "1 Cheeeee-hoooooo! The goal when going out is to eat something better than I could make myself. Absolutely nailed it.\n",
            "0 Even though hummus sounds boring, this version with seasoning and olives and assorted vegetables was incredible!\n",
            "0 A Beet burger didn’t sound too appetizing \n",
            "to me. However this was delicious! Fries were great too!\n",
            "2 One of my favorite dishes at Vanderbilt. It’s classic pho with the option to make it vegan (vegan broth and tofu for protein). There’s also an assortment of vegetables and spices to add. The base is traditional rice noodles. Overall very tasty and filling. #vivavanderbilt\n",
            "5 Airline food is pretty awful so #napafarms at #sfo was a great find. They have a ton of healthyish options and a lot of vegetarian stuff. Less fully vegan options but this hummus platter was the perfect thing for me and @mrsgarg to share! Crispy veggies, creamy hummus and some really nice toasted bread! Delish!\n",
            "1 This wrap is good, but very basic and nothing too exciting. I can tell it’s particularly healthy, which is good. #roosterredemption\n",
            "2 This wrap was very filling and had all sorts of tasty veggies in it! #roosterredemption #traderjoes\n",
            "1 A limited collab w sayangsonline! I wasn’t a huge fan of the sponge, it was kinda chewy/dense due to the low fat content I believe! The ‘cream’ was rly good, I put it in the fridge and it was like a block of dark chocolate. Cost $6.8 which is a bit over Budget for me but since its vegan + ethically sources all its ingredients its worth a try :)\n",
            "1 warm herbal noodle soup for lunch! friend dumped all her veggies on me hehe\n",
            "0 loved the soup!!! the food here is relatively cheap (~$4/5) and the ambience is nice\n",
            "2 Beans are under appreciated. Petai and tempe are two of my favorite bean foods. #crfsg\n",
            "2 Petai and tempe r two of my fave ingredients. And, despite the name, the dish isn’t very spicy. But, it is a bit too oily. You can request less oil. I forgot this time. #crfsg\n",
            "2 We loved this dish! (one vegan, one aspIrIng vegan) Warm delicious gooey cheese with a perfect crust - oh the flavours - wonderful to share! ☺️\n",
            "2 It’s bean soup whish is a pretty boring dish so my expectation was low. But it was insanely flavorful. I’d rlike commend it!\n",
            "1 Tasted pretty good. Wish there were more mushrooms that beans. It comes with mayo but I ordered without mayo so technically I ate a vegan version.  I’d recommend it for a good bean dish!\n",
            "3 The chocolate pie was so mouthwatering and delicious! The crust is buttery and flaky, the chocolate is creamy and smooth, and it has the perfect hint of orange flavor. I split it with my boyfriend for our anniversary dinner, but I wish I would have gotten my own! #roosterredemption\n",
            "2 I had this for dinner on my anniversary - it was so yummy! The “meatball” was the best part! Good flavor, a little spicy, and great texture. #roosterredemption\n",
            "1 Not totally what I expected, but very unique in a good way. Beautiful presentation. #roosterredemption\n",
            "2 I’ve only tried a few dishes at Fig + Farro (I’m sure they’re all fabulous) - but this one is AMAZING! I could get this delectable dish every time and be so happy. Each bite of this creamy filled ravioli makes me want more and more. This dish is a must try!!! #roosterredemption\n",
            "1 This was yummy! Great flavor and fresh pita bread to go with.\n",
            "2 This is a solid choice for an appetizer - the dip is creamy and cheesy, and the bread was so soft and yummy. #roosterredemption\n",
            "2 This could’ve been cheesier, but was still excellent. #crepeandspoon #Roosterredemption\n",
            "0 So good!! Lots of veggies to choose from to add to your scramble, and no extra charge for picking all of them.\n",
            "3 I had this dish mere hours before my doubles partner and I won a match in a tennis tournament. I don’t think it’s a coincidence! So much nutrition in this breakfast — which included mushrooms, tomatoes, and onions. 🎾 🤙 #HawaiiVegan\n",
            "0 Fantastic homemade vegan cheese and a unique, delicious scramble\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bean flavour',\n",
              " '#sgeats',\n",
              " '#mooncake',\n",
              " '#redbean',\n",
              " '#mooncake',\n",
              " 'butter knife',\n",
              " '#bestpicks',\n",
              " 'egg yolk',\n",
              " 'lotus paste',\n",
              " '#sgeats',\n",
              " '#mooncake',\n",
              " 'Soy fanática',\n",
              " 'unos ajíes',\n",
              " 'hor fun',\n",
              " '#neveragain',\n",
              " '#sgeats',\n",
              " '#horfun',\n",
              " 'size portions',\n",
              " 'bbq sauce',\n",
              " 'serve fix',\n",
              " 'tomato sauce',\n",
              " '#vivavanderbilt',\n",
              " 'Sesame ginger',\n",
              " 'vanilla bean',\n",
              " 'bean pastry',\n",
              " 'pastry cream',\n",
              " 'chocolate icing',\n",
              " 'Vanilla bean',\n",
              " 'bean cream',\n",
              " 'chocolate frosting',\n",
              " 'raspberry curd',\n",
              " 'curd filling',\n",
              " 'raspberry curd',\n",
              " 'vanilla icing',\n",
              " 'apple fritter',\n",
              " 'maple frosting',\n",
              " 'comfort food',\n",
              " 'Chick-un',\n",
              " '#comfortfood',\n",
              " '#bostonvegan',\n",
              " 'smoothie bowls',\n",
              " 'maqui berry',\n",
              " 'açaí berry',\n",
              " 'summer berries',\n",
              " 'almond butter',\n",
              " 'housemade granola',\n",
              " 'granola - and',\n",
              " 'breakfast option',\n",
              " '#smoothiebowl',\n",
              " 'smoothiebowl #',\n",
              " '#pressed',\n",
              " '#veganboston',\n",
              " 'ice cream',\n",
              " 'cream push',\n",
              " 'push pops',\n",
              " '#dessert',\n",
              " '#dessert',\n",
              " '#bychloe',\n",
              " 'cashew crema',\n",
              " 'crema sauce',\n",
              " '#nachos',\n",
              " '#veganamsterdam',\n",
              " 'dessert plate',\n",
              " 'apple struddle',\n",
              " 'dipping sauce',\n",
              " '#soberfish',\n",
              " '#Roosterredemption',\n",
              " '#soberfish',\n",
              " 'soberfish #',\n",
              " '#Roosterredemption',\n",
              " '#Roosterredemption',\n",
              " 'sushi roll',\n",
              " '#soberfish',\n",
              " '#Roosterredemption',\n",
              " '#sushi',\n",
              " 'sushi #',\n",
              " '#soberfish',\n",
              " '#soberfish',\n",
              " '#roosterredemption',\n",
              " '#soberfish',\n",
              " '#Roosterredemption',\n",
              " '#avianodenver',\n",
              " 'almond milk',\n",
              " '#oatly',\n",
              " '#cherrycreek',\n",
              " '#coffee',\n",
              " 'bean hummus',\n",
              " 'cucumber relish',\n",
              " '#roosterredemption',\n",
              " 'basil aioli',\n",
              " 'goat cheese',\n",
              " 'cooking time',\n",
              " '#roosterredemption',\n",
              " 'bell peppers',\n",
              " 'bell pepper',\n",
              " 'pepper flavor',\n",
              " '#vivavanderbilt',\n",
              " '#cookie',\n",
              " '#snack',\n",
              " 'Birthday cake',\n",
              " 'vanilla cake',\n",
              " 'chocolate frosting',\n",
              " 'vanilla-chocolate',\n",
              " 'chocolate chip',\n",
              " 'chip cake',\n",
              " 'vanilla icing',\n",
              " 'cookie dough',\n",
              " '#vegout',\n",
              " 'tofu bowl',\n",
              " 'quinoa base',\n",
              " 'tofu chunks',\n",
              " 'watermelon radish',\n",
              " 'cucumber slices',\n",
              " '#rpiveg',\n",
              " 'corn party',\n",
              " 'chipotle mayo',\n",
              " '#vivavanderbilt',\n",
              " 'veggie burger',\n",
              " '#vivavanderbilt',\n",
              " 'smoothie bowl',\n",
              " 'protein powder',\n",
              " 'protein powder',\n",
              " '#vivavanderbilt',\n",
              " 'avocado puree',\n",
              " 'macadamia nuts',\n",
              " 'lotus paste',\n",
              " 'egg yolk',\n",
              " 'avocado one',\n",
              " 'mooncake party',\n",
              " 'mango mochi',\n",
              " 'mochi dessert',\n",
              " 'mango pieces',\n",
              " '#kele',\n",
              " '#mango',\n",
              " '#mango',\n",
              " '#roosterredemption',\n",
              " 'dumpling flavour',\n",
              " 'fish dumplings',\n",
              " 'flavour combination',\n",
              " 'bbq sauce',\n",
              " 'plastic straws',\n",
              " 'mid-autumn',\n",
              " '-autumn',\n",
              " 'autumn festival',\n",
              " 'potato filling',\n",
              " 'artichoke heart',\n",
              " 'well-balanced',\n",
              " 'oat milk',\n",
              " 'milk options',\n",
              " 'veg options',\n",
              " 'non-vegan',\n",
              " 'brioche bun',\n",
              " 'whole-foods',\n",
              " 'foods veggie',\n",
              " 'veggie burger',\n",
              " 'side salad',\n",
              " '#laksa',\n",
              " '#sgeats',\n",
              " '#noodles',\n",
              " 'quality tofu',\n",
              " '#tofu',\n",
              " 'tofu #',\n",
              " '#sgeats',\n",
              " '#sgeats',\n",
              " 'rice porridge',\n",
              " 'tofu cubes',\n",
              " 'well-blended',\n",
              " 'laksa leaf',\n",
              " 'leaf fragrance',\n",
              " '#sgeats',\n",
              " '#vegancateringsg',\n",
              " '#curry',\n",
              " 'curry taste',\n",
              " '#sgeats',\n",
              " '#vegancateringsg',\n",
              " 'veggie nuggets',\n",
              " 'there - love',\n",
              " '#sgeats',\n",
              " '#vegancateringsg',\n",
              " 'curry flavour',\n",
              " '#sgeats',\n",
              " '#vegancateringsg',\n",
              " '#sgeats',\n",
              " '#vegancateringsg',\n",
              " '#vivavanderbilt',\n",
              " 'cream cheese',\n",
              " '#tofutti',\n",
              " '#hyvee',\n",
              " '#springfarmsanctuary',\n",
              " '#springfarmsanctuary',\n",
              " 'Cheeeee-hoooooo',\n",
              " 'rice noodles',\n",
              " '#vivavanderbilt',\n",
              " 'Airline food',\n",
              " '#napafarms',\n",
              " '#sfo',\n",
              " 'healthyish options',\n",
              " 'hummus platter',\n",
              " '#roosterredemption',\n",
              " '#roosterredemption',\n",
              " '#traderjoes',\n",
              " 'fat content',\n",
              " 'noodle soup',\n",
              " 'bean foods',\n",
              " '#crfsg',\n",
              " 'tempe r',\n",
              " '#crfsg',\n",
              " 'crust - oh',\n",
              " 'flavours - wonderful',\n",
              " 'bean soup',\n",
              " 'soup whish',\n",
              " 'bean dish',\n",
              " 'chocolate pie',\n",
              " 'anniversary dinner',\n",
              " '#roosterredemption',\n",
              " 'anniversary - it',\n",
              " '#roosterredemption',\n",
              " '#roosterredemption',\n",
              " ') - but',\n",
              " '#roosterredemption',\n",
              " 'pita bread',\n",
              " 'appetizer - the',\n",
              " '#roosterredemption',\n",
              " '#crepeandspoon',\n",
              " '#Roosterredemption',\n",
              " 'doubles partner',\n",
              " 'tennis tournament',\n",
              " '#HawaiiVegan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCqM4_80OrZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "7e9326cf-d799-4eb8-8c60-9fcbfe4a0f34"
      },
      "source": [
        "noun_chunks_list"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[It,\n",
              "  It,\n",
              "  aubergine and pepper pieces,\n",
              "  the aubergine,\n",
              "  The dish,\n",
              "  a party,\n",
              "  flavours],\n",
              " [a classic açaí bowl,\n",
              "  different fruit,\n",
              "  chia seeds,\n",
              "  coconut flakes,\n",
              "  granola,\n",
              "  açaí,\n",
              "  quite a large portion,\n",
              "  you,\n",
              "  the staff,\n",
              "  you,\n",
              "  they,\n",
              "  you,\n",
              "  the bowl,\n",
              "  plastic containers 🤗],\n",
              " [the açaí base,\n",
              "  the chia,\n",
              "  a bit more fruit,\n",
              "  top,\n",
              "  it,\n",
              "  the best açaí bowl,\n",
              "  i,\n",
              "  singapore,\n",
              "  they,\n",
              "  plastic cutlery,\n",
              "  bowls,\n",
              "  i,\n",
              "  it,\n",
              "  the shop],\n",
              " [Their acai, something, it, the granola],\n",
              " [granola,\n",
              "  chia seed,\n",
              "  blueberries,\n",
              "  banana,\n",
              "  coconut flakes,\n",
              "  they,\n",
              "  it,\n",
              "  cacao nibs 🙆‍♂]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcF9tufUyqah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}